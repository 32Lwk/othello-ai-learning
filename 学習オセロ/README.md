# オセロAI学習プログラム

Q学習を使用したオセロAIの学習プログラムです。人間vsAIの対戦やAI同士の訓練を通じて、AIがオセロの戦略を学習します。

## 機能

- **人間vsAIモード**: 人間プレイヤーとAIが対戦し、AIが学習
- **AI同士訓練モード**: AI同士で対戦させて事前訓練
- **Q学習**: 強化学習による戦略の自動学習
- **学習進捗表示**: 勝率推移グラフと統計情報の表示
- **モード選択画面**: 直感的なUIでモードと設定を選択

## 必要な環境

- Python 3.7以上
- Pygame

## セットアップ

1. リポジトリをクローン
```bash
git clone <repository-url>
cd 学習オセロ
```

2. 必要なパッケージをインストール
```bash
pip install pygame
```

3. プログラムを実行
```bash
python オセロ2.py
```

## 使い方

### モード選択
プログラム起動時にモード選択画面が表示されます：

- **人間vsAIで学習**: 人間プレイヤー（黒）とAI（白）が対戦
- **AI同士で訓練→人間vsAI**: AI同士で事前訓練後、人間vsAIモードに移行

### 設定オプション
- **デバッグモード**: 詳細なログ出力
- **AI描画**: AI同士の対戦時の描画ON/OFF
- **カスタム入力**: 訓練回数の設定
- **AI速度**: AIの思考時間調整

### ゲーム操作
- **マウスクリック**: 盤面に石を配置
- **リセットボタン**: 新しいゲームを開始
- **戻るボタン**: モード選択画面に戻る

## ファイル構成

- `オセロ2.py`: メインプログラム
- `learning_history.py`: 学習履歴管理
- `learning_logger.py`: 学習ログ管理
- `qtable_analyzer.py`: Qテーブル分析
- `qtable.pkl`: 学習済みQテーブル（自動生成）

## 学習アルゴリズム

### Q学習
- **学習率 (α)**: 0.1
- **割引率 (γ)**: 0.9
- **ε-greedy**: 0.1（探索確率）

### 報酬設計
- 石を裏返す: +1点
- 勝利: +100点
- 敗北: -100点
- 引き分け: +50点

## 画面構成

- **左側**: 学習進捗グラフと統計情報
- **右側**: オセロ盤面
- **下部**: メッセージとボタン

## 学習データ

- Qテーブルは自動的に保存・読み込みされます
- 学習履歴はJSON形式で保存されます
- プログラム終了時に自動保存されます

## ライセンス

このプロジェクトはMITライセンスの下で公開されています。

## 貢献

バグ報告や機能提案は、GitHubのIssuesページでお知らせください。

## 更新履歴

- v1.0: 初期リリース
  - Q学習によるオセロAI
  - 人間vsAIモード
  - AI同士訓練モード
  - 学習進捗表示 